{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tqdm\n",
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('news_train.csv')\n",
    "test = pd.read_csv('news_test.csv') \n",
    "submission = pd.read_csv('sample_submission.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.calibration import CalibratedClassifierCV \n",
    "\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import ensemble, metrics, model_selection, naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os \n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import matplotlib.pylab as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, Conv2DTranspose, MaxPooling2D, AveragePooling2D, BatchNormalization, concatenate, Input, ConvLSTM2D, Reshape, Conv3D, Flatten, LSTM, GRU, Dense,Dropout, Add\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import re \n",
    "\n",
    "import nltk # for stopwords \n",
    "from nltk.corpus import stopwords\n",
    "import gensim # for Word2Vec embeddings \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from konlpy.tag import Mecab, Hannanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>ord</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEWS02580</td>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
       "      <td>[이데일리 MARKETPOINT]15:32 현재 코스닥 기관 678억 순매도</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEWS02580</td>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
       "      <td>\"실적기반\" 저가에 매집해야 할 8월 급등유망주 TOP 5 전격공개</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEWS02580</td>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
       "      <td>하이스탁론, 선취수수료 없는 월 0.4% 최저금리 상품 출시</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEWS02580</td>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
       "      <td>종합 경제정보 미디어 이데일리 - 무단전재 &amp; 재배포 금지</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEWS09727</td>\n",
       "      <td>20200626</td>\n",
       "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
       "      <td>전국적인 소비 붐 조성에 기여할 예정</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_id      date                        title  \\\n",
       "0  NEWS02580  20200605          [마감]코스닥 기관 678억 순매도   \n",
       "1  NEWS02580  20200605          [마감]코스닥 기관 678억 순매도   \n",
       "2  NEWS02580  20200605          [마감]코스닥 기관 678억 순매도   \n",
       "3  NEWS02580  20200605          [마감]코스닥 기관 678억 순매도   \n",
       "4  NEWS09727  20200626  롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참   \n",
       "\n",
       "                                      content  ord  info  \n",
       "0  [이데일리 MARKETPOINT]15:32 현재 코스닥 기관 678억 순매도    1     0  \n",
       "1       \"실적기반\" 저가에 매집해야 할 8월 급등유망주 TOP 5 전격공개    2     1  \n",
       "2           하이스탁론, 선취수수료 없는 월 0.4% 최저금리 상품 출시    3     1  \n",
       "3            종합 경제정보 미디어 이데일리 - 무단전재 & 재배포 금지    4     0  \n",
       "4                        전국적인 소비 붐 조성에 기여할 예정    1     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>ord</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEWS00237</td>\n",
       "      <td>20200118</td>\n",
       "      <td>[주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대</td>\n",
       "      <td>마이크로 LED TV 장비 양산 돌입- 전방업체 투자 확대로 본업도 호조연일 '신고가'</td>\n",
       "      <td>1</td>\n",
       "      <td>NEWS00237_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEWS00237</td>\n",
       "      <td>20200118</td>\n",
       "      <td>[주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대</td>\n",
       "      <td>[이데일리 김대웅 기자] 반도체 장비 업체 코세스(089890)의 기술력이 마이크로...</td>\n",
       "      <td>2</td>\n",
       "      <td>NEWS00237_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEWS00237</td>\n",
       "      <td>20200118</td>\n",
       "      <td>[주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대</td>\n",
       "      <td>최근 대형 업체들과 거래를 맺고 관련 장비들의 양산에 돌입하면서 주가도 연일 신고가...</td>\n",
       "      <td>3</td>\n",
       "      <td>NEWS00237_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEWS00237</td>\n",
       "      <td>20200118</td>\n",
       "      <td>[주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대</td>\n",
       "      <td>TV를 필두로 올해부터 마이크로 LED의 시대가 본격적으로 개화할 것으로 예상되면서...</td>\n",
       "      <td>4</td>\n",
       "      <td>NEWS00237_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEWS00237</td>\n",
       "      <td>20200118</td>\n",
       "      <td>[주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대</td>\n",
       "      <td>코세스는 반도체 장비를 제조, 판매하는 업체로 지난 2006년 11월 코스닥 시장에...</td>\n",
       "      <td>5</td>\n",
       "      <td>NEWS00237_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_id      date                                title  \\\n",
       "0  NEWS00237  20200118  [주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대   \n",
       "1  NEWS00237  20200118  [주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대   \n",
       "2  NEWS00237  20200118  [주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대   \n",
       "3  NEWS00237  20200118  [주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대   \n",
       "4  NEWS00237  20200118  [주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대   \n",
       "\n",
       "                                             content  ord           id  \n",
       "0   마이크로 LED TV 장비 양산 돌입- 전방업체 투자 확대로 본업도 호조연일 '신고가'    1  NEWS00237_1  \n",
       "1  [이데일리 김대웅 기자] 반도체 장비 업체 코세스(089890)의 기술력이 마이크로...    2  NEWS00237_2  \n",
       "2  최근 대형 업체들과 거래를 맺고 관련 장비들의 양산에 돌입하면서 주가도 연일 신고가...    3  NEWS00237_3  \n",
       "3  TV를 필두로 올해부터 마이크로 LED의 시대가 본격적으로 개화할 것으로 예상되면서...    4  NEWS00237_4  \n",
       "4  코세스는 반도체 장비를 제조, 판매하는 업체로 지난 2006년 11월 코스닥 시장에...    5  NEWS00237_5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_labels = train['info'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(cnt_labels.index, cnt_labels.values, alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Real or Fake', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to do feature engineering. This consists of two main parts \n",
    "1. meta features: features that we extract from the text like number of words, number of punctuations, etc \n",
    "2. text based features: features directly based on the text/words like frequency, svd, word2vec, etc. \n",
    "\n",
    "I referred to [this analysis](https://dacon.io/competitions/official/235658/codeshare/1917?page=1&dtype=recent&ptype=pub) for more feature engineering ideas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title_tokenized'] = train['title'].apply(lambda x: mecab.morphs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['content_tokenized'] = train['content'].apply(lambda x: mecab.morphs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['title_tokenized'] = test['title'].apply(lambda x: mecab.morphs(x))\n",
    "test['content_tokenized'] = test['content'].apply(lambda x: mecab.morphs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words in title\n",
    "train['num_words_title'] = train['title_tokenized'].apply(lambda x: len(x)) \n",
    "test['num_words_title'] = test['title_tokenized'].apply(lambda x: len(x))   \n",
    "\n",
    "# number of words in content \n",
    "train['num_words_content'] = train['content_tokenized'].apply(lambda x: len(x)) \n",
    "test['num_words_content'] = test['content_tokenized'].apply(lambda x: len(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique words in title \n",
    "train['title_num_unique'] = train['title_tokenized'].apply(lambda x: len(set(x))) \n",
    "test['title_num_unique'] = test['title_tokenized'].apply(lambda x: len(set(x))) \n",
    "\n",
    "# number of unique words in content \n",
    "train['content_num_unique'] = train['content_tokenized'].apply(lambda x: len(set(x))) \n",
    "test['content_num_unique'] = test['content_tokenized'].apply(lambda x: len(set(x))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of punctuations in text \n",
    "train['num_punctuations_title'] = train['title_tokenized'].apply(lambda x: len([c for c in x if c in string.punctuation]))\n",
    "test['num_punctuations_title'] = test['title_tokenized'].apply(lambda x: len([c for c in x if c in string.punctuation]))\n",
    "\n",
    "train['num_punctuations_content'] = train['content_tokenized'].apply(lambda x: len([c for c in x if c in string.punctuation]))\n",
    "test['num_punctuations_content'] = test['content_tokenized'].apply(lambda x: len([c for c in x if c in string.punctuation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ 또는 (로 시작하는지에 대한 여부 \n",
    "train[\"title_startswith_[\"]=train.title.apply(lambda x : str(x).startswith(\"[\" ) or str(x).startswith(\"(\")) \n",
    "train[\"content_startswith_[\"]=train.content.apply(lambda x : str(x).startswith(\"[\" ) or str(x).startswith(\"(\") ) \n",
    "test[\"title_startswith_[\"]=test.title.apply(lambda x : str(x).startswith(\"[\" ) or str(x).startswith(\"(\")) \n",
    "test[\"content_startswith_[\"]=test.content.apply(lambda x : str(x).startswith(\"[\" ) or str(x).startswith(\"(\") ) \n",
    "\n",
    "\n",
    "# ] 또는 )로 시작하는지에 대한 여부 \n",
    "train[\"title_endswith_]\"]=train.title.apply(lambda x : str(x).endswith(\"]\" ) or str(x).endswith(\")\"))\n",
    "train[\"content_endswith_]\"]=train.content.apply(lambda x : str(x).endswith(\"]\" ) or str(x).endswith(\")\") )\n",
    "test[\"title_endswith_]\"]=test.title.apply(lambda x : str(x).endswith(\"]\" ) or str(x).endswith(\")\"))\n",
    "test[\"content_endswith_]\"]=test.content.apply(lambda x : str(x).endswith(\"]\" ) or str(x).endswith(\")\") )\n",
    "\n",
    "\n",
    "# ' 로 시작하는지에 대한 여부 \n",
    "train[\"title_startswith_quote\"]=train.title.apply(lambda x : str(x).startswith('\"'))\n",
    "train[\"content_startswith_quote\"]=train.content.apply(lambda x : str(x).startswith('\"'))\n",
    "test[\"title_startswith_quote\"]=test.title.apply(lambda x : str(x).startswith('\"'))\n",
    "test[\"content_startswith_quote\"]=test.content.apply(lambda x : str(x).startswith('\"'))\n",
    "\n",
    "\n",
    "# '로 끝나는지에 대한 여부\n",
    "train[\"title_endswith_quote\"]=train.title.apply(lambda x : str(x).endswith('\"'))\n",
    "train[\"content_endswith_quote\"]=train.content.apply(lambda x : str(x).endswith('\"'))\n",
    "test[\"title_endswith_quote\"]=test.title.apply(lambda x : str(x).endswith('\"'))\n",
    "test[\"content_endswith_quote\"]=test.content.apply(lambda x : str(x).endswith('\"'))\n",
    "\n",
    "\n",
    "# 숫자로 시작하는지에 대한 여부 \n",
    "train[\"title_startswith_number\"]=train.title.apply(lambda x : str(x)[0].isdigit())\n",
    "train[\"content_startswith_number\"]=train.content.apply(lambda x : str(x)[0].isdigit())\n",
    "test[\"title_startswith_number\"]=test.title.apply(lambda x : str(x)[0].isdigit())\n",
    "test[\"content_startswith_number\"]=test.content.apply(lambda x : str(x)[0].isdigit())\n",
    "\n",
    "\n",
    "# 숫자로 끝나는지에 대한 여부 \n",
    "train[\"title_endswith_number\"]=train.title.apply(lambda x : str(x)[-1].isdigit())\n",
    "train[\"content_endswith_number\"]=train.content.apply(lambda x : str(x)[-1].isdigit())\n",
    "test[\"title_endswith_number\"]=test.title.apply(lambda x : str(x)[-1].isdigit())\n",
    "test[\"content_endswith_number\"]=test.content.apply(lambda x : str(x)[-1].isdigit())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title length \n",
    "train[\"title_length\"] = train['title'].apply(lambda x : len(x))\n",
    "test[\"title_length\"] = test['title'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content length \n",
    "train['content_length'] = train['content'].apply(lambda x: len(x))\n",
    "test['content_length'] = test['content'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average length of word in title \n",
    "train['title_mean_length'] = train['title_tokenized'].apply(lambda x: np.mean([len(w) for w in x])) \n",
    "test['title_mean_length'] = test['title_tokenized'].apply(lambda x: np.mean([len(w) for w in x])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>ord</th>\n",
       "      <th>info</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>content_tokenized</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>num_words_content</th>\n",
       "      <th>...</th>\n",
       "      <th>content_startswith_quote</th>\n",
       "      <th>title_endswith_quote</th>\n",
       "      <th>content_endswith_quote</th>\n",
       "      <th>title_startswith_number</th>\n",
       "      <th>content_startswith_number</th>\n",
       "      <th>title_endswith_number</th>\n",
       "      <th>content_endswith_number</th>\n",
       "      <th>title_length</th>\n",
       "      <th>content_length</th>\n",
       "      <th>title_mean_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEWS02580</td>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
       "      <td>[이데일리 MARKETPOINT]15:32 현재 코스닥 기관 678억 순매도</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[, 마감, ], 코스닥, 기관, 678, 억, 순매도]</td>\n",
       "      <td>[[, 이, 데일리, MARKETPOINT, ], 15, :, 32, 현재, 코스닥...</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEWS02580</td>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
       "      <td>\"실적기반\" 저가에 매집해야 할 8월 급등유망주 TOP 5 전격공개</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[[, 마감, ], 코스닥, 기관, 678, 억, 순매도]</td>\n",
       "      <td>[\", 실적, 기반, \", 저, 가, 에, 매집, 해야, 할, 8, 월, 급등, 유...</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEWS02580</td>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
       "      <td>하이스탁론, 선취수수료 없는 월 0.4% 최저금리 상품 출시</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[[, 마감, ], 코스닥, 기관, 678, 억, 순매도]</td>\n",
       "      <td>[하이스, 탁론, ,, 선취, 수수료, 없, 는, 월, 0, ., 4, %, 최저,...</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEWS02580</td>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
       "      <td>종합 경제정보 미디어 이데일리 - 무단전재 &amp; 재배포 금지</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[[, 마감, ], 코스닥, 기관, 678, 억, 순매도]</td>\n",
       "      <td>[종합, 경제, 정보, 미디어, 이, 데일리, -, 무단, 전재, &amp;, 재, 배포,...</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEWS09727</td>\n",
       "      <td>20200626</td>\n",
       "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
       "      <td>전국적인 소비 붐 조성에 기여할 예정</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[롯데, ·, 공영, 등, 7, 개, TV, 홈, 쇼핑, 들, ,, 동행, 세일, 동참]</td>\n",
       "      <td>[전국, 적, 인, 소비, 붐, 조성, 에, 기여, 할, 예정]</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_id      date                        title  \\\n",
       "0  NEWS02580  20200605          [마감]코스닥 기관 678억 순매도   \n",
       "1  NEWS02580  20200605          [마감]코스닥 기관 678억 순매도   \n",
       "2  NEWS02580  20200605          [마감]코스닥 기관 678억 순매도   \n",
       "3  NEWS02580  20200605          [마감]코스닥 기관 678억 순매도   \n",
       "4  NEWS09727  20200626  롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참   \n",
       "\n",
       "                                      content  ord  info  \\\n",
       "0  [이데일리 MARKETPOINT]15:32 현재 코스닥 기관 678억 순매도    1     0   \n",
       "1       \"실적기반\" 저가에 매집해야 할 8월 급등유망주 TOP 5 전격공개    2     1   \n",
       "2           하이스탁론, 선취수수료 없는 월 0.4% 최저금리 상품 출시    3     1   \n",
       "3            종합 경제정보 미디어 이데일리 - 무단전재 & 재배포 금지    4     0   \n",
       "4                        전국적인 소비 붐 조성에 기여할 예정    1     0   \n",
       "\n",
       "                                     title_tokenized  \\\n",
       "0                   [[, 마감, ], 코스닥, 기관, 678, 억, 순매도]   \n",
       "1                   [[, 마감, ], 코스닥, 기관, 678, 억, 순매도]   \n",
       "2                   [[, 마감, ], 코스닥, 기관, 678, 억, 순매도]   \n",
       "3                   [[, 마감, ], 코스닥, 기관, 678, 억, 순매도]   \n",
       "4  [롯데, ·, 공영, 등, 7, 개, TV, 홈, 쇼핑, 들, ,, 동행, 세일, 동참]   \n",
       "\n",
       "                                   content_tokenized  num_words_title  \\\n",
       "0  [[, 이, 데일리, MARKETPOINT, ], 15, :, 32, 현재, 코스닥...                8   \n",
       "1  [\", 실적, 기반, \", 저, 가, 에, 매집, 해야, 할, 8, 월, 급등, 유...                8   \n",
       "2  [하이스, 탁론, ,, 선취, 수수료, 없, 는, 월, 0, ., 4, %, 최저,...                8   \n",
       "3  [종합, 경제, 정보, 미디어, 이, 데일리, -, 무단, 전재, &, 재, 배포,...                8   \n",
       "4                [전국, 적, 인, 소비, 붐, 조성, 에, 기여, 할, 예정]               14   \n",
       "\n",
       "   num_words_content  ...  content_startswith_quote  title_endswith_quote  \\\n",
       "0                 14  ...                     False                 False   \n",
       "1                 18  ...                      True                 False   \n",
       "2                 16  ...                     False                 False   \n",
       "3                 13  ...                     False                 False   \n",
       "4                 10  ...                     False                 False   \n",
       "\n",
       "   content_endswith_quote  title_startswith_number  content_startswith_number  \\\n",
       "0                   False                    False                      False   \n",
       "1                   False                    False                      False   \n",
       "2                   False                    False                      False   \n",
       "3                   False                    False                      False   \n",
       "4                   False                    False                      False   \n",
       "\n",
       "   title_endswith_number  content_endswith_number  title_length  \\\n",
       "0                  False                    False            19   \n",
       "1                  False                    False            19   \n",
       "2                  False                    False            19   \n",
       "3                  False                    False            19   \n",
       "4                  False                    False            27   \n",
       "\n",
       "   content_length  title_mean_length  \n",
       "0              42                2.0  \n",
       "1              37                2.0  \n",
       "2              33                2.0  \n",
       "3              32                2.0  \n",
       "4              20                1.5  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>ord</th>\n",
       "      <th>id</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>content_tokenized</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>num_words_content</th>\n",
       "      <th>...</th>\n",
       "      <th>content_startswith_quote</th>\n",
       "      <th>title_endswith_quote</th>\n",
       "      <th>content_endswith_quote</th>\n",
       "      <th>title_startswith_number</th>\n",
       "      <th>content_startswith_number</th>\n",
       "      <th>title_endswith_number</th>\n",
       "      <th>content_endswith_number</th>\n",
       "      <th>title_length</th>\n",
       "      <th>content_length</th>\n",
       "      <th>title_mean_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEWS00237</td>\n",
       "      <td>20200118</td>\n",
       "      <td>[주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대</td>\n",
       "      <td>마이크로 LED TV 장비 양산 돌입- 전방업체 투자 확대로 본업도 호조연일 '신고가'</td>\n",
       "      <td>1</td>\n",
       "      <td>NEWS00237_1</td>\n",
       "      <td>[[, 주목, !, e, 스몰, 캡, ], 코, 세스, ,, 마이크, 로, LED,...</td>\n",
       "      <td>[마이크, 로, LED, TV, 장비, 양산, 돌입, -, 전방, 업체, 투자, 확...</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>48</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEWS00237</td>\n",
       "      <td>20200118</td>\n",
       "      <td>[주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대</td>\n",
       "      <td>[이데일리 김대웅 기자] 반도체 장비 업체 코세스(089890)의 기술력이 마이크로...</td>\n",
       "      <td>2</td>\n",
       "      <td>NEWS00237_2</td>\n",
       "      <td>[[, 주목, !, e, 스몰, 캡, ], 코, 세스, ,, 마이크, 로, LED,...</td>\n",
       "      <td>[[, 이, 데일리, 김대웅, 기자, ], 반도체, 장비, 업체, 코, 세스, (,...</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>76</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEWS00237</td>\n",
       "      <td>20200118</td>\n",
       "      <td>[주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대</td>\n",
       "      <td>최근 대형 업체들과 거래를 맺고 관련 장비들의 양산에 돌입하면서 주가도 연일 신고가...</td>\n",
       "      <td>3</td>\n",
       "      <td>NEWS00237_3</td>\n",
       "      <td>[[, 주목, !, e, 스몰, 캡, ], 코, 세스, ,, 마이크, 로, LED,...</td>\n",
       "      <td>[최근, 대형, 업체, 들, 과, 거래, 를, 맺, 고, 관련, 장비, 들, 의, ...</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEWS00237</td>\n",
       "      <td>20200118</td>\n",
       "      <td>[주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대</td>\n",
       "      <td>TV를 필두로 올해부터 마이크로 LED의 시대가 본격적으로 개화할 것으로 예상되면서...</td>\n",
       "      <td>4</td>\n",
       "      <td>NEWS00237_4</td>\n",
       "      <td>[[, 주목, !, e, 스몰, 캡, ], 코, 세스, ,, 마이크, 로, LED,...</td>\n",
       "      <td>[TV, 를, 필두, 로, 올해, 부터, 마이크, 로, LED, 의, 시대, 가, ...</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>76</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEWS00237</td>\n",
       "      <td>20200118</td>\n",
       "      <td>[주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대</td>\n",
       "      <td>코세스는 반도체 장비를 제조, 판매하는 업체로 지난 2006년 11월 코스닥 시장에...</td>\n",
       "      <td>5</td>\n",
       "      <td>NEWS00237_5</td>\n",
       "      <td>[[, 주목, !, e, 스몰, 캡, ], 코, 세스, ,, 마이크, 로, LED,...</td>\n",
       "      <td>[코, 세스, 는, 반도체, 장비, 를, 제조, ,, 판매, 하, 는, 업체, 로,...</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>102</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_id      date                                title  \\\n",
       "0  NEWS00237  20200118  [주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대   \n",
       "1  NEWS00237  20200118  [주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대   \n",
       "2  NEWS00237  20200118  [주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대   \n",
       "3  NEWS00237  20200118  [주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대   \n",
       "4  NEWS00237  20200118  [주목!e스몰캡]코세스, 마이크로LED 시장 개화 최대수혜 기대   \n",
       "\n",
       "                                             content  ord           id  \\\n",
       "0   마이크로 LED TV 장비 양산 돌입- 전방업체 투자 확대로 본업도 호조연일 '신고가'    1  NEWS00237_1   \n",
       "1  [이데일리 김대웅 기자] 반도체 장비 업체 코세스(089890)의 기술력이 마이크로...    2  NEWS00237_2   \n",
       "2  최근 대형 업체들과 거래를 맺고 관련 장비들의 양산에 돌입하면서 주가도 연일 신고가...    3  NEWS00237_3   \n",
       "3  TV를 필두로 올해부터 마이크로 LED의 시대가 본격적으로 개화할 것으로 예상되면서...    4  NEWS00237_4   \n",
       "4  코세스는 반도체 장비를 제조, 판매하는 업체로 지난 2006년 11월 코스닥 시장에...    5  NEWS00237_5   \n",
       "\n",
       "                                     title_tokenized  \\\n",
       "0  [[, 주목, !, e, 스몰, 캡, ], 코, 세스, ,, 마이크, 로, LED,...   \n",
       "1  [[, 주목, !, e, 스몰, 캡, ], 코, 세스, ,, 마이크, 로, LED,...   \n",
       "2  [[, 주목, !, e, 스몰, 캡, ], 코, 세스, ,, 마이크, 로, LED,...   \n",
       "3  [[, 주목, !, e, 스몰, 캡, ], 코, 세스, ,, 마이크, 로, LED,...   \n",
       "4  [[, 주목, !, e, 스몰, 캡, ], 코, 세스, ,, 마이크, 로, LED,...   \n",
       "\n",
       "                                   content_tokenized  num_words_title  \\\n",
       "0  [마이크, 로, LED, TV, 장비, 양산, 돌입, -, 전방, 업체, 투자, 확...               18   \n",
       "1  [[, 이, 데일리, 김대웅, 기자, ], 반도체, 장비, 업체, 코, 세스, (,...               18   \n",
       "2  [최근, 대형, 업체, 들, 과, 거래, 를, 맺, 고, 관련, 장비, 들, 의, ...               18   \n",
       "3  [TV, 를, 필두, 로, 올해, 부터, 마이크, 로, LED, 의, 시대, 가, ...               18   \n",
       "4  [코, 세스, 는, 반도체, 장비, 를, 제조, ,, 판매, 하, 는, 업체, 로,...               18   \n",
       "\n",
       "   num_words_content  ...  content_startswith_quote  title_endswith_quote  \\\n",
       "0                 21  ...                     False                 False   \n",
       "1                 33  ...                     False                 False   \n",
       "2                 28  ...                     False                 False   \n",
       "3                 37  ...                     False                 False   \n",
       "4                 48  ...                     False                 False   \n",
       "\n",
       "   content_endswith_quote  title_startswith_number  content_startswith_number  \\\n",
       "0                   False                    False                      False   \n",
       "1                   False                    False                      False   \n",
       "2                   False                    False                      False   \n",
       "3                   False                    False                      False   \n",
       "4                   False                    False                      False   \n",
       "\n",
       "   title_endswith_number  content_endswith_number  title_length  \\\n",
       "0                  False                    False            35   \n",
       "1                  False                    False            35   \n",
       "2                  False                    False            35   \n",
       "3                  False                    False            35   \n",
       "4                  False                    False            35   \n",
       "\n",
       "   content_length  title_mean_length  \n",
       "0              48           1.666667  \n",
       "1              76           1.666667  \n",
       "2              56           1.666667  \n",
       "3              76           1.666667  \n",
       "4             102           1.666667  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118745, 29), (142565, 29))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Text Based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract TF-IDF 1-3 ngram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_tokenizer(text):  \n",
    "    tokens_mecab = mecab.morphs(text) \n",
    "    return tokens_mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for singular value decomposition  \n",
    "tfidf_vec = TfidfVectorizer(tokenizer = mecab_tokenizer, ngram_range = (1,3)) \n",
    "full_tfidf_title = tfidf_vec.fit_transform(train['title'].values.tolist() + test['title'].values.tolist())\n",
    "train_tfidf_title = tfidf_vec.transform(train['title'].values.tolist()) \n",
    "test_tfidf_title = tfidf_vec.transform(test['title'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((261310, 170537), (118745, 170537), (142565, 170537))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_tfidf_title.shape, train_tfidf_title.shape, test_tfidf_title.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for singular value decomposition  \n",
    "tfidf_vec = TfidfVectorizer(tokenizer = mecab_tokenizer, ngram_range = (1,3)) \n",
    "full_tfidf_content = tfidf_vec.fit_transform(train['content'].values.tolist() + test['content'].values.tolist())\n",
    "train_tfidf_content = tfidf_vec.transform(train['content'].values.tolist()) \n",
    "test_tfidf_content = tfidf_vec.transform(test['content'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((261310, 2465227), (118745, 2465227), (142565, 2465227))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_tfidf_content.shape, train_tfidf_content.shape, test_tfidf_content.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_obj = TruncatedSVD(n_components = 20, algorithm = 'arpack') \n",
    "svd_obj.fit(full_tfidf_title)\n",
    "train_svd_title = pd.DataFrame(svd_obj.transform(train_tfidf_title)) \n",
    "test_svd_title = pd.DataFrame(svd_obj.transform(test_tfidf_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_svd_title.columns = ['svd_word_title_' + str(i) for i in range(20)] \n",
    "test_svd_title.columns = ['svd_word_title_' + str(i) for i in range(20)] \n",
    "\n",
    "train = pd.concat([train, train_svd_title], axis = 1) \n",
    "test = pd.concat([test, test_svd_title], axis = 1)  \n",
    "\n",
    "del full_tfidf_title, train_tfidf_title, test_tfidf_title, train_svd_title, test_svd_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_obj = TruncatedSVD(n_components = 20, algorithm = 'arpack') \n",
    "svd_obj.fit(full_tfidf_content) \n",
    "train_svd_content = pd.DataFrame(svd_obj.transform(train_tfidf_content)) \n",
    "test_svd_content = pd.DataFrame(svd_obj.transform(test_tfidf_content)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_svd_content.columns = ['svd_word_content_' + str(i) for i in range(20)] \n",
    "test_svd_content.columns = ['svd_word_content_' + str(i) for i in range(20)] \n",
    "\n",
    "train = pd.concat([train, train_svd_content], axis = 1) \n",
    "test = pd.concat([test, test_svd_content], axis = 1)  \n",
    "\n",
    "del full_tfidf_content, train_tfidf_content, test_tfidf_content, train_svd_content, test_svd_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118745, 69), (142565, 69))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(['n_id','info', 'title', 'content', 'title_tokenized', 'content_tokenized'],axis=1) \n",
    "y_train = train['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.drop(['n_id','id','title', 'content', 'title_tokenized', 'content_tokenized'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.asarray(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118745, 63), (118745,), (142565, 63))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will begin training at this step, but to make our dataset stronger, we can add predictions from other models to our list of features as well. For example, we can use count vectorizer to extract word count information from the corpus and fit and predict using multinomial NB, then add the predicted results to our dataset and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 37546, number of negative: 57450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11473\n",
      "[LightGBM] [Info] Number of data points in the train set: 94996, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.395238 -> initscore=-0.425348\n",
      "[LightGBM] [Info] Start training from score -0.425348\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.589135\n",
      "[20]\tvalid_0's binary_logloss: 0.52097\n",
      "[30]\tvalid_0's binary_logloss: 0.464232\n",
      "[40]\tvalid_0's binary_logloss: 0.415491\n",
      "[50]\tvalid_0's binary_logloss: 0.373814\n",
      "[60]\tvalid_0's binary_logloss: 0.337826\n",
      "[70]\tvalid_0's binary_logloss: 0.306447\n",
      "[80]\tvalid_0's binary_logloss: 0.279052\n",
      "[90]\tvalid_0's binary_logloss: 0.254734\n",
      "[100]\tvalid_0's binary_logloss: 0.233166\n",
      "[110]\tvalid_0's binary_logloss: 0.214057\n",
      "[120]\tvalid_0's binary_logloss: 0.197096\n",
      "[130]\tvalid_0's binary_logloss: 0.181868\n",
      "[140]\tvalid_0's binary_logloss: 0.168316\n",
      "[150]\tvalid_0's binary_logloss: 0.156185\n",
      "[160]\tvalid_0's binary_logloss: 0.145184\n",
      "[170]\tvalid_0's binary_logloss: 0.135341\n",
      "[180]\tvalid_0's binary_logloss: 0.126441\n",
      "[190]\tvalid_0's binary_logloss: 0.118358\n",
      "[200]\tvalid_0's binary_logloss: 0.111137\n",
      "[210]\tvalid_0's binary_logloss: 0.104499\n",
      "[220]\tvalid_0's binary_logloss: 0.0985324\n",
      "[230]\tvalid_0's binary_logloss: 0.0931218\n",
      "[240]\tvalid_0's binary_logloss: 0.0881736\n",
      "[250]\tvalid_0's binary_logloss: 0.0836775\n",
      "[260]\tvalid_0's binary_logloss: 0.0795549\n",
      "[270]\tvalid_0's binary_logloss: 0.0758654\n",
      "[280]\tvalid_0's binary_logloss: 0.0724198\n",
      "[290]\tvalid_0's binary_logloss: 0.0693467\n",
      "[300]\tvalid_0's binary_logloss: 0.0664715\n",
      "[310]\tvalid_0's binary_logloss: 0.0637116\n",
      "[320]\tvalid_0's binary_logloss: 0.06127\n",
      "[330]\tvalid_0's binary_logloss: 0.0590523\n",
      "[340]\tvalid_0's binary_logloss: 0.0569829\n",
      "[350]\tvalid_0's binary_logloss: 0.0550503\n",
      "[360]\tvalid_0's binary_logloss: 0.053273\n",
      "[370]\tvalid_0's binary_logloss: 0.051651\n",
      "[380]\tvalid_0's binary_logloss: 0.0501157\n",
      "[390]\tvalid_0's binary_logloss: 0.0486666\n",
      "[400]\tvalid_0's binary_logloss: 0.0473007\n",
      "[410]\tvalid_0's binary_logloss: 0.0461113\n",
      "[420]\tvalid_0's binary_logloss: 0.044958\n",
      "[430]\tvalid_0's binary_logloss: 0.0439161\n",
      "[440]\tvalid_0's binary_logloss: 0.0429167\n",
      "[450]\tvalid_0's binary_logloss: 0.0419823\n",
      "[460]\tvalid_0's binary_logloss: 0.0410645\n",
      "[470]\tvalid_0's binary_logloss: 0.0403026\n",
      "[480]\tvalid_0's binary_logloss: 0.0395339\n",
      "[490]\tvalid_0's binary_logloss: 0.038817\n",
      "[500]\tvalid_0's binary_logloss: 0.0381286\n",
      "[510]\tvalid_0's binary_logloss: 0.0375085\n",
      "[520]\tvalid_0's binary_logloss: 0.0368841\n",
      "[530]\tvalid_0's binary_logloss: 0.0363139\n",
      "[540]\tvalid_0's binary_logloss: 0.0357601\n",
      "[550]\tvalid_0's binary_logloss: 0.0352216\n",
      "[560]\tvalid_0's binary_logloss: 0.0347255\n",
      "[570]\tvalid_0's binary_logloss: 0.0341542\n",
      "[580]\tvalid_0's binary_logloss: 0.0336399\n",
      "[590]\tvalid_0's binary_logloss: 0.0332239\n",
      "[600]\tvalid_0's binary_logloss: 0.0327602\n",
      "[610]\tvalid_0's binary_logloss: 0.0323363\n",
      "[620]\tvalid_0's binary_logloss: 0.0319578\n",
      "[630]\tvalid_0's binary_logloss: 0.03161\n",
      "[640]\tvalid_0's binary_logloss: 0.0312952\n",
      "[650]\tvalid_0's binary_logloss: 0.0309432\n",
      "[660]\tvalid_0's binary_logloss: 0.0306546\n",
      "[670]\tvalid_0's binary_logloss: 0.0303413\n",
      "[680]\tvalid_0's binary_logloss: 0.0300333\n",
      "[690]\tvalid_0's binary_logloss: 0.0297554\n",
      "[700]\tvalid_0's binary_logloss: 0.0294404\n",
      "[710]\tvalid_0's binary_logloss: 0.0291001\n",
      "[720]\tvalid_0's binary_logloss: 0.0288247\n",
      "[730]\tvalid_0's binary_logloss: 0.0285889\n",
      "[740]\tvalid_0's binary_logloss: 0.0283174\n",
      "[750]\tvalid_0's binary_logloss: 0.0280465\n",
      "[760]\tvalid_0's binary_logloss: 0.0278458\n",
      "[770]\tvalid_0's binary_logloss: 0.0275897\n",
      "[780]\tvalid_0's binary_logloss: 0.0273148\n",
      "[790]\tvalid_0's binary_logloss: 0.0270693\n",
      "[800]\tvalid_0's binary_logloss: 0.0269153\n",
      "[810]\tvalid_0's binary_logloss: 0.0267347\n",
      "[820]\tvalid_0's binary_logloss: 0.0265308\n",
      "[830]\tvalid_0's binary_logloss: 0.0263571\n",
      "[840]\tvalid_0's binary_logloss: 0.0261864\n",
      "[850]\tvalid_0's binary_logloss: 0.0259482\n",
      "[860]\tvalid_0's binary_logloss: 0.0257845\n",
      "[870]\tvalid_0's binary_logloss: 0.0256441\n",
      "[880]\tvalid_0's binary_logloss: 0.0254574\n",
      "[890]\tvalid_0's binary_logloss: 0.0252964\n",
      "[900]\tvalid_0's binary_logloss: 0.0251548\n",
      "[910]\tvalid_0's binary_logloss: 0.0250345\n",
      "[920]\tvalid_0's binary_logloss: 0.0248587\n",
      "[930]\tvalid_0's binary_logloss: 0.0247112\n",
      "[940]\tvalid_0's binary_logloss: 0.0245624\n",
      "[950]\tvalid_0's binary_logloss: 0.0244337\n",
      "[960]\tvalid_0's binary_logloss: 0.0242964\n",
      "[970]\tvalid_0's binary_logloss: 0.0241457\n",
      "[980]\tvalid_0's binary_logloss: 0.0240067\n",
      "[990]\tvalid_0's binary_logloss: 0.0238677\n",
      "[1000]\tvalid_0's binary_logloss: 0.0237007\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0237007\n",
      "[LightGBM] [Info] Number of positive: 37546, number of negative: 57450\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11475\n",
      "[LightGBM] [Info] Number of data points in the train set: 94996, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.395238 -> initscore=-0.425348\n",
      "[LightGBM] [Info] Start training from score -0.425348\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.589056\n",
      "[20]\tvalid_0's binary_logloss: 0.520735\n",
      "[30]\tvalid_0's binary_logloss: 0.463731\n",
      "[40]\tvalid_0's binary_logloss: 0.415027\n",
      "[50]\tvalid_0's binary_logloss: 0.373244\n",
      "[60]\tvalid_0's binary_logloss: 0.337084\n",
      "[70]\tvalid_0's binary_logloss: 0.305625\n",
      "[80]\tvalid_0's binary_logloss: 0.278062\n",
      "[90]\tvalid_0's binary_logloss: 0.2535\n",
      "[100]\tvalid_0's binary_logloss: 0.231721\n",
      "[110]\tvalid_0's binary_logloss: 0.21246\n",
      "[120]\tvalid_0's binary_logloss: 0.195477\n",
      "[130]\tvalid_0's binary_logloss: 0.180102\n",
      "[140]\tvalid_0's binary_logloss: 0.16639\n",
      "[150]\tvalid_0's binary_logloss: 0.154133\n",
      "[160]\tvalid_0's binary_logloss: 0.143023\n",
      "[170]\tvalid_0's binary_logloss: 0.133042\n",
      "[180]\tvalid_0's binary_logloss: 0.124082\n",
      "[190]\tvalid_0's binary_logloss: 0.115937\n",
      "[200]\tvalid_0's binary_logloss: 0.108576\n",
      "[210]\tvalid_0's binary_logloss: 0.101932\n",
      "[220]\tvalid_0's binary_logloss: 0.0959557\n",
      "[230]\tvalid_0's binary_logloss: 0.0905122\n",
      "[240]\tvalid_0's binary_logloss: 0.0855522\n",
      "[250]\tvalid_0's binary_logloss: 0.0810534\n",
      "[260]\tvalid_0's binary_logloss: 0.0768758\n",
      "[270]\tvalid_0's binary_logloss: 0.0730729\n",
      "[280]\tvalid_0's binary_logloss: 0.0695819\n",
      "[290]\tvalid_0's binary_logloss: 0.0664134\n",
      "[300]\tvalid_0's binary_logloss: 0.0635406\n",
      "[310]\tvalid_0's binary_logloss: 0.0608026\n",
      "[320]\tvalid_0's binary_logloss: 0.0583692\n",
      "[330]\tvalid_0's binary_logloss: 0.0560681\n",
      "[340]\tvalid_0's binary_logloss: 0.0539363\n",
      "[350]\tvalid_0's binary_logloss: 0.0520122\n",
      "[360]\tvalid_0's binary_logloss: 0.0502162\n",
      "[370]\tvalid_0's binary_logloss: 0.0485638\n",
      "[380]\tvalid_0's binary_logloss: 0.0470032\n",
      "[390]\tvalid_0's binary_logloss: 0.0455749\n",
      "[400]\tvalid_0's binary_logloss: 0.0442275\n",
      "[410]\tvalid_0's binary_logloss: 0.0429844\n",
      "[420]\tvalid_0's binary_logloss: 0.0418206\n",
      "[430]\tvalid_0's binary_logloss: 0.0407644\n",
      "[440]\tvalid_0's binary_logloss: 0.0397172\n",
      "[450]\tvalid_0's binary_logloss: 0.0387989\n",
      "[460]\tvalid_0's binary_logloss: 0.0379323\n",
      "[470]\tvalid_0's binary_logloss: 0.0370791\n",
      "[480]\tvalid_0's binary_logloss: 0.0362566\n",
      "[490]\tvalid_0's binary_logloss: 0.0355198\n",
      "[500]\tvalid_0's binary_logloss: 0.0348163\n",
      "[510]\tvalid_0's binary_logloss: 0.0341705\n",
      "[520]\tvalid_0's binary_logloss: 0.0335681\n",
      "[530]\tvalid_0's binary_logloss: 0.0329619\n",
      "[540]\tvalid_0's binary_logloss: 0.0324114\n",
      "[550]\tvalid_0's binary_logloss: 0.0318946\n",
      "[560]\tvalid_0's binary_logloss: 0.031424\n",
      "[570]\tvalid_0's binary_logloss: 0.0309508\n",
      "[580]\tvalid_0's binary_logloss: 0.0304597\n",
      "[590]\tvalid_0's binary_logloss: 0.0300562\n",
      "[600]\tvalid_0's binary_logloss: 0.0296497\n",
      "[610]\tvalid_0's binary_logloss: 0.0292324\n",
      "[620]\tvalid_0's binary_logloss: 0.0288649\n",
      "[630]\tvalid_0's binary_logloss: 0.0284855\n",
      "[640]\tvalid_0's binary_logloss: 0.0280863\n",
      "[650]\tvalid_0's binary_logloss: 0.0277327\n",
      "[660]\tvalid_0's binary_logloss: 0.0273782\n",
      "[670]\tvalid_0's binary_logloss: 0.0270577\n",
      "[680]\tvalid_0's binary_logloss: 0.0267518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[690]\tvalid_0's binary_logloss: 0.0264561\n",
      "[700]\tvalid_0's binary_logloss: 0.0261684\n",
      "[710]\tvalid_0's binary_logloss: 0.0258538\n",
      "[720]\tvalid_0's binary_logloss: 0.0255845\n",
      "[730]\tvalid_0's binary_logloss: 0.0253361\n",
      "[740]\tvalid_0's binary_logloss: 0.0250834\n",
      "[750]\tvalid_0's binary_logloss: 0.0248246\n",
      "[760]\tvalid_0's binary_logloss: 0.0245935\n",
      "[770]\tvalid_0's binary_logloss: 0.0243232\n",
      "[780]\tvalid_0's binary_logloss: 0.0241029\n",
      "[790]\tvalid_0's binary_logloss: 0.023888\n",
      "[800]\tvalid_0's binary_logloss: 0.0236639\n",
      "[810]\tvalid_0's binary_logloss: 0.0234545\n",
      "[820]\tvalid_0's binary_logloss: 0.0232634\n",
      "[830]\tvalid_0's binary_logloss: 0.0229961\n",
      "[840]\tvalid_0's binary_logloss: 0.0228175\n",
      "[850]\tvalid_0's binary_logloss: 0.0226524\n",
      "[860]\tvalid_0's binary_logloss: 0.0224915\n",
      "[870]\tvalid_0's binary_logloss: 0.0223084\n",
      "[880]\tvalid_0's binary_logloss: 0.0221172\n",
      "[890]\tvalid_0's binary_logloss: 0.0219433\n",
      "[900]\tvalid_0's binary_logloss: 0.0218131\n",
      "[910]\tvalid_0's binary_logloss: 0.0216097\n",
      "[920]\tvalid_0's binary_logloss: 0.0214385\n",
      "[930]\tvalid_0's binary_logloss: 0.0212673\n",
      "[940]\tvalid_0's binary_logloss: 0.0211183\n",
      "[950]\tvalid_0's binary_logloss: 0.0209998\n",
      "[960]\tvalid_0's binary_logloss: 0.0208786\n",
      "[970]\tvalid_0's binary_logloss: 0.0207647\n",
      "[980]\tvalid_0's binary_logloss: 0.0206156\n",
      "[990]\tvalid_0's binary_logloss: 0.0204967\n",
      "[1000]\tvalid_0's binary_logloss: 0.0203442\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0203442\n",
      "[LightGBM] [Info] Number of positive: 37546, number of negative: 57450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11472\n",
      "[LightGBM] [Info] Number of data points in the train set: 94996, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.395238 -> initscore=-0.425348\n",
      "[LightGBM] [Info] Start training from score -0.425348\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.589247\n",
      "[20]\tvalid_0's binary_logloss: 0.521138\n",
      "[30]\tvalid_0's binary_logloss: 0.464455\n",
      "[40]\tvalid_0's binary_logloss: 0.415962\n",
      "[50]\tvalid_0's binary_logloss: 0.37438\n",
      "[60]\tvalid_0's binary_logloss: 0.338415\n",
      "[70]\tvalid_0's binary_logloss: 0.307081\n",
      "[80]\tvalid_0's binary_logloss: 0.279635\n",
      "[90]\tvalid_0's binary_logloss: 0.255211\n",
      "[100]\tvalid_0's binary_logloss: 0.233673\n",
      "[110]\tvalid_0's binary_logloss: 0.214628\n",
      "[120]\tvalid_0's binary_logloss: 0.197717\n",
      "[130]\tvalid_0's binary_logloss: 0.182568\n",
      "[140]\tvalid_0's binary_logloss: 0.168944\n",
      "[150]\tvalid_0's binary_logloss: 0.156728\n",
      "[160]\tvalid_0's binary_logloss: 0.145769\n",
      "[170]\tvalid_0's binary_logloss: 0.135888\n",
      "[180]\tvalid_0's binary_logloss: 0.127025\n",
      "[190]\tvalid_0's binary_logloss: 0.118962\n",
      "[200]\tvalid_0's binary_logloss: 0.111744\n",
      "[210]\tvalid_0's binary_logloss: 0.10522\n",
      "[220]\tvalid_0's binary_logloss: 0.0992426\n",
      "[230]\tvalid_0's binary_logloss: 0.0938919\n",
      "[240]\tvalid_0's binary_logloss: 0.0889665\n",
      "[250]\tvalid_0's binary_logloss: 0.0844354\n",
      "[260]\tvalid_0's binary_logloss: 0.0803771\n",
      "[270]\tvalid_0's binary_logloss: 0.0766508\n",
      "[280]\tvalid_0's binary_logloss: 0.0732292\n",
      "[290]\tvalid_0's binary_logloss: 0.0700831\n",
      "[300]\tvalid_0's binary_logloss: 0.0671877\n",
      "[310]\tvalid_0's binary_logloss: 0.064558\n",
      "[320]\tvalid_0's binary_logloss: 0.0620592\n",
      "[330]\tvalid_0's binary_logloss: 0.0598407\n",
      "[340]\tvalid_0's binary_logloss: 0.0577463\n",
      "[350]\tvalid_0's binary_logloss: 0.0556799\n",
      "[360]\tvalid_0's binary_logloss: 0.0537548\n",
      "[370]\tvalid_0's binary_logloss: 0.0520797\n",
      "[380]\tvalid_0's binary_logloss: 0.0504679\n",
      "[390]\tvalid_0's binary_logloss: 0.0489205\n",
      "[400]\tvalid_0's binary_logloss: 0.0476161\n",
      "[410]\tvalid_0's binary_logloss: 0.0463712\n",
      "[420]\tvalid_0's binary_logloss: 0.0451912\n",
      "[430]\tvalid_0's binary_logloss: 0.0441512\n",
      "[440]\tvalid_0's binary_logloss: 0.0431044\n",
      "[450]\tvalid_0's binary_logloss: 0.0421478\n",
      "[460]\tvalid_0's binary_logloss: 0.0412442\n",
      "[470]\tvalid_0's binary_logloss: 0.0403271\n",
      "[480]\tvalid_0's binary_logloss: 0.0395425\n",
      "[490]\tvalid_0's binary_logloss: 0.038826\n",
      "[500]\tvalid_0's binary_logloss: 0.0381625\n",
      "[510]\tvalid_0's binary_logloss: 0.0374963\n",
      "[520]\tvalid_0's binary_logloss: 0.03684\n",
      "[530]\tvalid_0's binary_logloss: 0.036262\n",
      "[540]\tvalid_0's binary_logloss: 0.0356854\n",
      "[550]\tvalid_0's binary_logloss: 0.03519\n",
      "[560]\tvalid_0's binary_logloss: 0.0346724\n",
      "[570]\tvalid_0's binary_logloss: 0.0341954\n",
      "[580]\tvalid_0's binary_logloss: 0.0337464\n",
      "[590]\tvalid_0's binary_logloss: 0.0332697\n",
      "[600]\tvalid_0's binary_logloss: 0.0327464\n",
      "[610]\tvalid_0's binary_logloss: 0.0323008\n",
      "[620]\tvalid_0's binary_logloss: 0.0319579\n",
      "[630]\tvalid_0's binary_logloss: 0.0315787\n",
      "[640]\tvalid_0's binary_logloss: 0.0312002\n",
      "[650]\tvalid_0's binary_logloss: 0.0308619\n",
      "[660]\tvalid_0's binary_logloss: 0.0305349\n",
      "[670]\tvalid_0's binary_logloss: 0.0302067\n",
      "[680]\tvalid_0's binary_logloss: 0.0298867\n",
      "[690]\tvalid_0's binary_logloss: 0.029621\n",
      "[700]\tvalid_0's binary_logloss: 0.0293436\n",
      "[710]\tvalid_0's binary_logloss: 0.0290579\n",
      "[720]\tvalid_0's binary_logloss: 0.0287733\n",
      "[730]\tvalid_0's binary_logloss: 0.0284684\n",
      "[740]\tvalid_0's binary_logloss: 0.0282085\n",
      "[750]\tvalid_0's binary_logloss: 0.0279068\n",
      "[760]\tvalid_0's binary_logloss: 0.0276813\n",
      "[770]\tvalid_0's binary_logloss: 0.0274772\n",
      "[780]\tvalid_0's binary_logloss: 0.0272673\n",
      "[790]\tvalid_0's binary_logloss: 0.027043\n",
      "[800]\tvalid_0's binary_logloss: 0.0267585\n",
      "[810]\tvalid_0's binary_logloss: 0.026589\n",
      "[820]\tvalid_0's binary_logloss: 0.0263717\n",
      "[830]\tvalid_0's binary_logloss: 0.0261853\n",
      "[840]\tvalid_0's binary_logloss: 0.0259864\n",
      "[850]\tvalid_0's binary_logloss: 0.025787\n",
      "[860]\tvalid_0's binary_logloss: 0.0255602\n",
      "[870]\tvalid_0's binary_logloss: 0.0253613\n",
      "[880]\tvalid_0's binary_logloss: 0.0251813\n",
      "[890]\tvalid_0's binary_logloss: 0.0250006\n",
      "[900]\tvalid_0's binary_logloss: 0.0248709\n",
      "[910]\tvalid_0's binary_logloss: 0.0247266\n",
      "[920]\tvalid_0's binary_logloss: 0.0245665\n",
      "[930]\tvalid_0's binary_logloss: 0.0244743\n",
      "[940]\tvalid_0's binary_logloss: 0.0242944\n",
      "[950]\tvalid_0's binary_logloss: 0.0241516\n",
      "[960]\tvalid_0's binary_logloss: 0.0240195\n",
      "[970]\tvalid_0's binary_logloss: 0.0238953\n",
      "[980]\tvalid_0's binary_logloss: 0.0237218\n",
      "[990]\tvalid_0's binary_logloss: 0.023631\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234927\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0234927\n",
      "[LightGBM] [Info] Number of positive: 37545, number of negative: 57451\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11474\n",
      "[LightGBM] [Info] Number of data points in the train set: 94996, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.395227 -> initscore=-0.425392\n",
      "[LightGBM] [Info] Start training from score -0.425392\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.589309\n",
      "[20]\tvalid_0's binary_logloss: 0.52136\n",
      "[30]\tvalid_0's binary_logloss: 0.464757\n",
      "[40]\tvalid_0's binary_logloss: 0.416296\n",
      "[50]\tvalid_0's binary_logloss: 0.374731\n",
      "[60]\tvalid_0's binary_logloss: 0.33886\n",
      "[70]\tvalid_0's binary_logloss: 0.307384\n",
      "[80]\tvalid_0's binary_logloss: 0.280034\n",
      "[90]\tvalid_0's binary_logloss: 0.255568\n",
      "[100]\tvalid_0's binary_logloss: 0.234073\n",
      "[110]\tvalid_0's binary_logloss: 0.215003\n",
      "[120]\tvalid_0's binary_logloss: 0.197912\n",
      "[130]\tvalid_0's binary_logloss: 0.18271\n",
      "[140]\tvalid_0's binary_logloss: 0.169136\n",
      "[150]\tvalid_0's binary_logloss: 0.156937\n",
      "[160]\tvalid_0's binary_logloss: 0.145952\n",
      "[170]\tvalid_0's binary_logloss: 0.13605\n",
      "[180]\tvalid_0's binary_logloss: 0.127148\n",
      "[190]\tvalid_0's binary_logloss: 0.119113\n",
      "[200]\tvalid_0's binary_logloss: 0.111847\n",
      "[210]\tvalid_0's binary_logloss: 0.105207\n",
      "[220]\tvalid_0's binary_logloss: 0.0990925\n",
      "[230]\tvalid_0's binary_logloss: 0.0934243\n",
      "[240]\tvalid_0's binary_logloss: 0.088428\n",
      "[250]\tvalid_0's binary_logloss: 0.0839397\n",
      "[260]\tvalid_0's binary_logloss: 0.0797517\n",
      "[270]\tvalid_0's binary_logloss: 0.0759731\n",
      "[280]\tvalid_0's binary_logloss: 0.0724419\n",
      "[290]\tvalid_0's binary_logloss: 0.0691119\n",
      "[300]\tvalid_0's binary_logloss: 0.0661369\n",
      "[310]\tvalid_0's binary_logloss: 0.0633961\n",
      "[320]\tvalid_0's binary_logloss: 0.0608406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330]\tvalid_0's binary_logloss: 0.0584622\n",
      "[340]\tvalid_0's binary_logloss: 0.0562787\n",
      "[350]\tvalid_0's binary_logloss: 0.0542773\n",
      "[360]\tvalid_0's binary_logloss: 0.0524449\n",
      "[370]\tvalid_0's binary_logloss: 0.0507168\n",
      "[380]\tvalid_0's binary_logloss: 0.0491455\n",
      "[390]\tvalid_0's binary_logloss: 0.0476881\n",
      "[400]\tvalid_0's binary_logloss: 0.0463665\n",
      "[410]\tvalid_0's binary_logloss: 0.045127\n",
      "[420]\tvalid_0's binary_logloss: 0.0439906\n",
      "[430]\tvalid_0's binary_logloss: 0.0428791\n",
      "[440]\tvalid_0's binary_logloss: 0.0418763\n",
      "[450]\tvalid_0's binary_logloss: 0.0408834\n",
      "[460]\tvalid_0's binary_logloss: 0.0399612\n",
      "[470]\tvalid_0's binary_logloss: 0.0391164\n",
      "[480]\tvalid_0's binary_logloss: 0.0383429\n",
      "[490]\tvalid_0's binary_logloss: 0.0375649\n",
      "[500]\tvalid_0's binary_logloss: 0.036826\n",
      "[510]\tvalid_0's binary_logloss: 0.0361775\n",
      "[520]\tvalid_0's binary_logloss: 0.0355279\n",
      "[530]\tvalid_0's binary_logloss: 0.0348988\n",
      "[540]\tvalid_0's binary_logloss: 0.0343827\n",
      "[550]\tvalid_0's binary_logloss: 0.0338415\n",
      "[560]\tvalid_0's binary_logloss: 0.0333285\n",
      "[570]\tvalid_0's binary_logloss: 0.0328555\n",
      "[580]\tvalid_0's binary_logloss: 0.0324212\n",
      "[590]\tvalid_0's binary_logloss: 0.0319575\n",
      "[600]\tvalid_0's binary_logloss: 0.0315007\n",
      "[610]\tvalid_0's binary_logloss: 0.0310213\n",
      "[620]\tvalid_0's binary_logloss: 0.0306126\n",
      "[630]\tvalid_0's binary_logloss: 0.0301979\n",
      "[640]\tvalid_0's binary_logloss: 0.0298037\n",
      "[650]\tvalid_0's binary_logloss: 0.0294664\n",
      "[660]\tvalid_0's binary_logloss: 0.0291194\n",
      "[670]\tvalid_0's binary_logloss: 0.0287871\n",
      "[680]\tvalid_0's binary_logloss: 0.0284439\n",
      "[690]\tvalid_0's binary_logloss: 0.0280332\n",
      "[700]\tvalid_0's binary_logloss: 0.0277832\n",
      "[710]\tvalid_0's binary_logloss: 0.02748\n",
      "[720]\tvalid_0's binary_logloss: 0.027199\n",
      "[730]\tvalid_0's binary_logloss: 0.0269129\n",
      "[740]\tvalid_0's binary_logloss: 0.0266797\n",
      "[750]\tvalid_0's binary_logloss: 0.0264306\n",
      "[760]\tvalid_0's binary_logloss: 0.0262072\n",
      "[770]\tvalid_0's binary_logloss: 0.0259938\n",
      "[780]\tvalid_0's binary_logloss: 0.0258171\n",
      "[790]\tvalid_0's binary_logloss: 0.0255748\n",
      "[800]\tvalid_0's binary_logloss: 0.0253478\n",
      "[810]\tvalid_0's binary_logloss: 0.0250869\n",
      "[820]\tvalid_0's binary_logloss: 0.0249099\n",
      "[830]\tvalid_0's binary_logloss: 0.0247462\n",
      "[840]\tvalid_0's binary_logloss: 0.024572\n",
      "[850]\tvalid_0's binary_logloss: 0.0244095\n",
      "[860]\tvalid_0's binary_logloss: 0.0241805\n",
      "[870]\tvalid_0's binary_logloss: 0.024005\n",
      "[880]\tvalid_0's binary_logloss: 0.02377\n",
      "[890]\tvalid_0's binary_logloss: 0.0235687\n",
      "[900]\tvalid_0's binary_logloss: 0.0234231\n",
      "[910]\tvalid_0's binary_logloss: 0.023269\n",
      "[920]\tvalid_0's binary_logloss: 0.0231545\n",
      "[930]\tvalid_0's binary_logloss: 0.0230483\n",
      "[940]\tvalid_0's binary_logloss: 0.0228523\n",
      "[950]\tvalid_0's binary_logloss: 0.0226989\n",
      "[960]\tvalid_0's binary_logloss: 0.0225728\n",
      "[970]\tvalid_0's binary_logloss: 0.0224528\n",
      "[980]\tvalid_0's binary_logloss: 0.0223063\n",
      "[990]\tvalid_0's binary_logloss: 0.0222069\n",
      "[1000]\tvalid_0's binary_logloss: 0.0220587\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0220587\n",
      "[LightGBM] [Info] Number of positive: 37545, number of negative: 57451\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11478\n",
      "[LightGBM] [Info] Number of data points in the train set: 94996, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.395227 -> initscore=-0.425392\n",
      "[LightGBM] [Info] Start training from score -0.425392\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.589229\n",
      "[20]\tvalid_0's binary_logloss: 0.521422\n",
      "[30]\tvalid_0's binary_logloss: 0.464989\n",
      "[40]\tvalid_0's binary_logloss: 0.416702\n",
      "[50]\tvalid_0's binary_logloss: 0.375327\n",
      "[60]\tvalid_0's binary_logloss: 0.339469\n",
      "[70]\tvalid_0's binary_logloss: 0.308354\n",
      "[80]\tvalid_0's binary_logloss: 0.281009\n",
      "[90]\tvalid_0's binary_logloss: 0.256632\n",
      "[100]\tvalid_0's binary_logloss: 0.235075\n",
      "[110]\tvalid_0's binary_logloss: 0.216068\n",
      "[120]\tvalid_0's binary_logloss: 0.199065\n",
      "[130]\tvalid_0's binary_logloss: 0.18393\n",
      "[140]\tvalid_0's binary_logloss: 0.170423\n",
      "[150]\tvalid_0's binary_logloss: 0.158369\n",
      "[160]\tvalid_0's binary_logloss: 0.147394\n",
      "[170]\tvalid_0's binary_logloss: 0.137628\n",
      "[180]\tvalid_0's binary_logloss: 0.128771\n",
      "[190]\tvalid_0's binary_logloss: 0.120725\n",
      "[200]\tvalid_0's binary_logloss: 0.113456\n",
      "[210]\tvalid_0's binary_logloss: 0.106969\n",
      "[220]\tvalid_0's binary_logloss: 0.101037\n",
      "[230]\tvalid_0's binary_logloss: 0.0955517\n",
      "[240]\tvalid_0's binary_logloss: 0.0905968\n",
      "[250]\tvalid_0's binary_logloss: 0.0860799\n",
      "[260]\tvalid_0's binary_logloss: 0.082008\n",
      "[270]\tvalid_0's binary_logloss: 0.0782738\n",
      "[280]\tvalid_0's binary_logloss: 0.0749242\n",
      "[290]\tvalid_0's binary_logloss: 0.07168\n",
      "[300]\tvalid_0's binary_logloss: 0.0688108\n",
      "[310]\tvalid_0's binary_logloss: 0.0661097\n",
      "[320]\tvalid_0's binary_logloss: 0.063659\n",
      "[330]\tvalid_0's binary_logloss: 0.0612727\n",
      "[340]\tvalid_0's binary_logloss: 0.0591057\n",
      "[350]\tvalid_0's binary_logloss: 0.0571226\n",
      "[360]\tvalid_0's binary_logloss: 0.0552955\n",
      "[370]\tvalid_0's binary_logloss: 0.053598\n",
      "[380]\tvalid_0's binary_logloss: 0.0520456\n",
      "[390]\tvalid_0's binary_logloss: 0.0505812\n",
      "[400]\tvalid_0's binary_logloss: 0.0491627\n",
      "[410]\tvalid_0's binary_logloss: 0.0479556\n",
      "[420]\tvalid_0's binary_logloss: 0.0467684\n",
      "[430]\tvalid_0's binary_logloss: 0.0456775\n",
      "[440]\tvalid_0's binary_logloss: 0.0446732\n",
      "[450]\tvalid_0's binary_logloss: 0.0436907\n",
      "[460]\tvalid_0's binary_logloss: 0.0427881\n",
      "[470]\tvalid_0's binary_logloss: 0.041925\n",
      "[480]\tvalid_0's binary_logloss: 0.0410523\n",
      "[490]\tvalid_0's binary_logloss: 0.0403002\n",
      "[500]\tvalid_0's binary_logloss: 0.0395788\n",
      "[510]\tvalid_0's binary_logloss: 0.0389561\n",
      "[520]\tvalid_0's binary_logloss: 0.0383382\n",
      "[530]\tvalid_0's binary_logloss: 0.0377367\n",
      "[540]\tvalid_0's binary_logloss: 0.0371625\n",
      "[550]\tvalid_0's binary_logloss: 0.0366189\n",
      "[560]\tvalid_0's binary_logloss: 0.0360871\n",
      "[570]\tvalid_0's binary_logloss: 0.0355778\n",
      "[580]\tvalid_0's binary_logloss: 0.0350221\n",
      "[590]\tvalid_0's binary_logloss: 0.034545\n",
      "[600]\tvalid_0's binary_logloss: 0.034131\n",
      "[610]\tvalid_0's binary_logloss: 0.0337018\n",
      "[620]\tvalid_0's binary_logloss: 0.0332651\n",
      "[630]\tvalid_0's binary_logloss: 0.0329036\n",
      "[640]\tvalid_0's binary_logloss: 0.0324636\n",
      "[650]\tvalid_0's binary_logloss: 0.0320701\n",
      "[660]\tvalid_0's binary_logloss: 0.031747\n",
      "[670]\tvalid_0's binary_logloss: 0.0313653\n",
      "[680]\tvalid_0's binary_logloss: 0.031101\n",
      "[690]\tvalid_0's binary_logloss: 0.0307546\n",
      "[700]\tvalid_0's binary_logloss: 0.0304616\n",
      "[710]\tvalid_0's binary_logloss: 0.0301246\n",
      "[720]\tvalid_0's binary_logloss: 0.0298575\n",
      "[730]\tvalid_0's binary_logloss: 0.0295878\n",
      "[740]\tvalid_0's binary_logloss: 0.0293291\n",
      "[750]\tvalid_0's binary_logloss: 0.0290777\n",
      "[760]\tvalid_0's binary_logloss: 0.0287937\n",
      "[770]\tvalid_0's binary_logloss: 0.0284636\n",
      "[780]\tvalid_0's binary_logloss: 0.0282144\n",
      "[790]\tvalid_0's binary_logloss: 0.0279948\n",
      "[800]\tvalid_0's binary_logloss: 0.0278321\n",
      "[810]\tvalid_0's binary_logloss: 0.0275509\n",
      "[820]\tvalid_0's binary_logloss: 0.0273707\n",
      "[830]\tvalid_0's binary_logloss: 0.0272061\n",
      "[840]\tvalid_0's binary_logloss: 0.0270417\n",
      "[850]\tvalid_0's binary_logloss: 0.0267761\n",
      "[860]\tvalid_0's binary_logloss: 0.0265815\n",
      "[870]\tvalid_0's binary_logloss: 0.0263968\n",
      "[880]\tvalid_0's binary_logloss: 0.0261752\n",
      "[890]\tvalid_0's binary_logloss: 0.0259912\n",
      "[900]\tvalid_0's binary_logloss: 0.0258583\n",
      "[910]\tvalid_0's binary_logloss: 0.0257271\n",
      "[920]\tvalid_0's binary_logloss: 0.0255975\n",
      "[930]\tvalid_0's binary_logloss: 0.0254578\n",
      "[940]\tvalid_0's binary_logloss: 0.0253036\n",
      "[950]\tvalid_0's binary_logloss: 0.0251778\n",
      "[960]\tvalid_0's binary_logloss: 0.0250198\n",
      "[970]\tvalid_0's binary_logloss: 0.0249052\n",
      "[980]\tvalid_0's binary_logloss: 0.0247481\n",
      "[990]\tvalid_0's binary_logloss: 0.0245492\n",
      "[1000]\tvalid_0's binary_logloss: 0.0244586\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0244586\n"
     ]
    }
   ],
   "source": [
    "k = 5 \n",
    "models = [] \n",
    "kfold = StratifiedKFold(n_splits = k, shuffle = True, random_state = 990101) \n",
    "for n_fold, (train_idx, val_idx) in enumerate(kfold.split(x_train, y_train)): \n",
    "    train_x, val_x = x_train[train_idx], x_train[val_idx]\n",
    "    train_y, val_y = y_train[train_idx], y_train[val_idx] \n",
    "    \n",
    "    params = {'learning_rate': 0.01,\n",
    "              'max_depth': 16, \n",
    "              'objective': 'binary',\n",
    "              'metric': 'binary_logloss',\n",
    "              'is_training_metric': True,\n",
    "              'num_leaves': 128,\n",
    "              'feature_fraction': 0.9,\n",
    "              'bagging_fraction': 0.75, \n",
    "              'bagging_freq': 5,\n",
    "              'seed': 960418} \n",
    "    \n",
    "    train_ds = lgbm.Dataset(train_x, label = train_y) \n",
    "    val_ds = lgbm.Dataset(val_x, label = val_y) \n",
    "    model = lgbm.train(params, train_ds, 1000, val_ds, verbose_eval = 10, early_stopping_rounds = 100) \n",
    "    models.append(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions \n",
    "pred1 = models[0].predict(x_test)\n",
    "pred2 = models[1].predict(x_test)\n",
    "pred3 = models[2].predict(x_test) \n",
    "pred4 = models[3].predict(x_test) \n",
    "pred5 = models[4].predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_avg = (pred1 + pred2 + pred3 + pred4 + pred5)/5.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pred = np.where(pred_avg > 0.5, 1, 0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['info'] = class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEWS00237_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEWS00237_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEWS00237_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEWS00237_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEWS00237_5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  info\n",
       "0  NEWS00237_1     0\n",
       "1  NEWS00237_2     0\n",
       "2  NEWS00237_3     0\n",
       "3  NEWS00237_4     0\n",
       "4  NEWS00237_5     0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lightgbm_63_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
