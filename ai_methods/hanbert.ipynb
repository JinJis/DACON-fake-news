{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "from transformers import BertModel\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed text data \n",
    "train_data = np.load('./storage/fintech_nlp/train_text_morphed.npy', allow_pickle = True) \n",
    "test_data = np.load('./storage/fintech_nlp/test_text_morphed.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./storage/fintech_nlp/lgbm_train_df.csv') \n",
    "y_train = train_df['info'] \n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118745,), (118745,), (142565,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, y_train.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to train tokenizer on full data \n",
    "full_data = np.concatenate([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128 \n",
    "input_sequences = tokenizer.texts_to_sequences(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = pad_sequences(input_sequences, \n",
    "                                maxlen = MAX_LEN, dtype = 'long', \n",
    "                                truncating = 'post', padding = 'post') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = [] \n",
    "for seq in input_sequences: \n",
    "    seq_mask = [float(i > 0) for i in seq] \n",
    "    attention_masks.append(seq_mask) \n",
    "\n",
    "attention_masks = np.asarray(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_sequences = tokenizer.texts_to_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_sequences = pad_sequences(test_input_sequences, \n",
    "                                maxlen = MAX_LEN, dtype = 'long', \n",
    "                                truncating = 'post', padding = 'post') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attention_masks = [] \n",
    "for seq in test_input_sequences: \n",
    "    seq_mask = [float(i > 0) for i in seq] \n",
    "    test_attention_masks.append(seq_mask) \n",
    "\n",
    "test_attention_masks = np.asarray(test_attention_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split and prepare for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simple train-validation split\n",
    "train_id, val_id, train_y, val_y = train_test_split(input_sequences, y_train, random_state = 42, test_size = 0.1) \n",
    "\n",
    "train_mask, val_mask, _, _ = train_test_split(attention_masks, input_sequences, random_state = 42, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106870, 128), (106870, 128), (106870,), (11875, 128), (11875, 128), (11875,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id.shape, train_mask.shape, train_y.shape, val_id.shape, val_mask.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = torch.tensor(train_id) \n",
    "train_y = torch.tensor(train_y) \n",
    "train_mask = torch.tensor(train_mask) \n",
    "\n",
    "val_id = torch.tensor(val_id) \n",
    "val_y = torch.tensor(val_y) \n",
    "val_mask = torch.tensor(val_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([106870, 128]),\n",
       " torch.Size([106870]),\n",
       " torch.Size([106870, 128]),\n",
       " torch.Size([11875, 128]),\n",
       " torch.Size([11875]),\n",
       " torch.Size([11875, 128]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id.shape, train_y.shape, train_mask.shape, val_id.shape, val_y.shape, val_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 \n",
    "train_set = TensorDataset(train_id, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_set)\n",
    "train_dataloader = DataLoader(train_set, sampler=train_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = TensorDataset(val_id, val_mask, val_y) \n",
    "val_sampler = SequentialSampler(val_set)\n",
    "val_dataloader = DataLoader(val_set, sampler=val_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBERTModel(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(CustomBERTModel, self).__init__() \n",
    "        self.bert = BertModel.from_pretrained('HanBert-54kN-torch')\n",
    "        self.dropout = nn.Dropout(0.2) \n",
    "        self.linear1 = nn.Linear(768,256)\n",
    "        self.linear2 = nn.Linear(256,1) \n",
    "        self.output = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        sequence_output, pooled_output = self.bert(ids, \n",
    "                                                   attention_mask=mask).values()\n",
    "        #linear1_output = self.linear1(sequence_output[:,0,:].view(-1,768))  \n",
    "        dropout = self.dropout(sequence_output)\n",
    "        linear1_output = self.linear1(sequence_output[:,0,:].view(-1,768)) \n",
    "        linear2_output = self.linear2(linear1_output) \n",
    "        logit = self.output(linear2_output) \n",
    "        return logit   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBERTModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(54000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear1): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (output): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomBERTModel() \n",
    "model.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "criterion = nn.BCELoss()\n",
    "#optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters())) \n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률\n",
    "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    "                )\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현을 위해 랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 20 ========\n",
      "Training...\n",
      "  Batch   100  of    835.    Elapsed: 0:02:20.\n",
      "  current loss = 0.12086381763219833\n",
      "  Batch   200  of    835.    Elapsed: 0:04:43.\n",
      "  current loss = 0.06908093392848969\n",
      "  Batch   300  of    835.    Elapsed: 0:07:06.\n",
      "  current loss = 0.11486254632472992\n",
      "  Batch   400  of    835.    Elapsed: 0:09:29.\n",
      "  current loss = 0.061554186046123505\n",
      "  Batch   500  of    835.    Elapsed: 0:11:52.\n",
      "  current loss = 0.04220367968082428\n",
      "  Batch   600  of    835.    Elapsed: 0:14:16.\n",
      "  current loss = 0.031889986246824265\n",
      "  Batch   700  of    835.    Elapsed: 0:16:39.\n",
      "  current loss = 0.07420255988836288\n",
      "  Batch   800  of    835.    Elapsed: 0:19:02.\n",
      "  current loss = 0.05796804651618004\n",
      "Average training loss = 0.08807991882563083\n",
      "Average training accuracy = 0.9654635643966305\n",
      "\n",
      "Running Validation ...\n",
      "Average validation loss = 0.040440571752266695\n",
      "Average validation accuracy = 0.9884666558053655\n",
      "saving model...\n",
      "\n",
      "======== Epoch 2 / 20 ========\n",
      "Training...\n",
      "  Batch   100  of    835.    Elapsed: 0:02:22.\n",
      "  current loss = 0.04223611578345299\n",
      "  Batch   200  of    835.    Elapsed: 0:04:45.\n",
      "  current loss = 0.0043540881015360355\n",
      "  Batch   300  of    835.    Elapsed: 0:07:07.\n",
      "  current loss = 0.018868278712034225\n",
      "  Batch   400  of    835.    Elapsed: 0:09:30.\n",
      "  current loss = 0.1108919009566307\n",
      "  Batch   500  of    835.    Elapsed: 0:11:53.\n",
      "  current loss = 0.011048274114727974\n",
      "  Batch   600  of    835.    Elapsed: 0:14:16.\n",
      "  current loss = 0.0023180036805570126\n",
      "  Batch   700  of    835.    Elapsed: 0:16:39.\n",
      "  current loss = 0.09029659628868103\n",
      "  Batch   800  of    835.    Elapsed: 0:19:02.\n",
      "  current loss = 0.03664109855890274\n",
      "Average training loss = 0.027647433463556546\n",
      "Average training accuracy = 0.9905875748502994\n",
      "\n",
      "Running Validation ...\n",
      "Average validation loss = 0.02760424671859871\n",
      "Average validation accuracy = 0.9922715053763441\n",
      "saving model...\n",
      "\n",
      "======== Epoch 3 / 20 ========\n",
      "Training...\n",
      "  Batch   100  of    835.    Elapsed: 0:02:22.\n",
      "  current loss = 0.01277050282806158\n",
      "  Batch   200  of    835.    Elapsed: 0:04:44.\n",
      "  current loss = 0.012827346101403236\n",
      "  Batch   300  of    835.    Elapsed: 0:07:06.\n",
      "  current loss = 0.006990018300712109\n",
      "  Batch   400  of    835.    Elapsed: 0:09:28.\n",
      "  current loss = 0.00023130138288252056\n",
      "  Batch   500  of    835.    Elapsed: 0:11:50.\n",
      "  current loss = 0.0010352195240557194\n",
      "  Batch   600  of    835.    Elapsed: 0:14:13.\n",
      "  current loss = 0.0012806126615032554\n",
      "  Batch   700  of    835.    Elapsed: 0:16:35.\n",
      "  current loss = 0.013647805899381638\n",
      "  Batch   800  of    835.    Elapsed: 0:18:57.\n",
      "  current loss = 0.004954413045197725\n",
      "Average training loss = 0.012975825643674735\n",
      "Average training accuracy = 0.9957038782604284\n",
      "\n",
      "Running Validation ...\n",
      "Average validation loss = 0.03728178642718034\n",
      "Average validation accuracy = 0.9924989138698816\n",
      "saving model...\n",
      "\n",
      "======== Epoch 4 / 20 ========\n",
      "Training...\n",
      "  Batch   100  of    835.    Elapsed: 0:02:21.\n",
      "  current loss = 0.00014815450413152575\n",
      "  Batch   200  of    835.    Elapsed: 0:04:43.\n",
      "  current loss = 0.00016522049554623663\n",
      "  Batch   300  of    835.    Elapsed: 0:07:05.\n",
      "  current loss = 0.0024078120477497578\n",
      "  Batch   400  of    835.    Elapsed: 0:09:27.\n",
      "  current loss = 0.0002588088682387024\n",
      "  Batch   500  of    835.    Elapsed: 0:11:49.\n",
      "  current loss = 0.00027799431700259447\n",
      "  Batch   600  of    835.    Elapsed: 0:14:11.\n",
      "  current loss = 0.0022730708587914705\n",
      "  Batch   700  of    835.    Elapsed: 0:16:33.\n",
      "  current loss = 0.0017715668072924018\n",
      "  Batch   800  of    835.    Elapsed: 0:18:55.\n",
      "  current loss = 0.0005084340809844434\n",
      "Average training loss = 0.007543852832547388\n",
      "Average training accuracy = 0.997501078351771\n",
      "\n",
      "Running Validation ...\n",
      "Average validation loss = 0.03116988031744709\n",
      "Average validation accuracy = 0.9930029461279462\n",
      "saving model...\n",
      "\n",
      "======== Epoch 5 / 20 ========\n",
      "Training...\n",
      "  Batch   100  of    835.    Elapsed: 0:02:21.\n",
      "  current loss = 9.942613542079926e-05\n",
      "  Batch   200  of    835.    Elapsed: 0:04:43.\n",
      "  current loss = 0.0001868797407951206\n",
      "  Batch   300  of    835.    Elapsed: 0:07:05.\n",
      "  current loss = 0.00012108771625207737\n",
      "  Batch   400  of    835.    Elapsed: 0:09:27.\n",
      "  current loss = 0.003794036339968443\n",
      "  Batch   500  of    835.    Elapsed: 0:11:49.\n",
      "  current loss = 0.00027616939041763544\n",
      "  Batch   600  of    835.    Elapsed: 0:14:11.\n",
      "  current loss = 0.00014344073133543134\n",
      "  Batch   700  of    835.    Elapsed: 0:16:33.\n",
      "  current loss = 0.018984360620379448\n",
      "  Batch   800  of    835.    Elapsed: 0:18:55.\n",
      "  current loss = 0.00019520981004461646\n",
      "Average training loss = 0.004848223919284437\n",
      "Average training accuracy = 0.9986714071856287\n",
      "\n",
      "Running Validation ...\n",
      "Average validation loss = 0.03941138194143908\n",
      "Average validation accuracy = 0.9920788869881612\n",
      "saving model...\n",
      "\n",
      "======== Epoch 6 / 20 ========\n",
      "Training...\n",
      "  Batch   100  of    835.    Elapsed: 0:02:21.\n",
      "  current loss = 0.00025657095829956234\n",
      "  Batch   200  of    835.    Elapsed: 0:04:43.\n",
      "  current loss = 0.00281245494261384\n",
      "  Batch   300  of    835.    Elapsed: 0:07:05.\n",
      "  current loss = 4.204934521112591e-05\n",
      "  Batch   400  of    835.    Elapsed: 0:09:27.\n",
      "  current loss = 6.660330109298229e-05\n",
      "  Batch   500  of    835.    Elapsed: 0:11:49.\n",
      "  current loss = 0.0004392525879666209\n",
      "  Batch   600  of    835.    Elapsed: 0:14:11.\n",
      "  current loss = 2.7578877052292228e-05\n",
      "  Batch   700  of    835.    Elapsed: 0:16:33.\n",
      "  current loss = 0.039761733263731\n",
      "  Batch   800  of    835.    Elapsed: 0:18:55.\n",
      "  current loss = 2.2206508219824173e-05\n",
      "Average training loss = 0.00308705134083359\n",
      "Average training accuracy = 0.9990550149700599\n",
      "\n",
      "Running Validation ...\n",
      "Average validation loss = 0.04765100499043324\n",
      "Average validation accuracy = 0.9940356182795699\n",
      "saving model...\n",
      "\n",
      "======== Epoch 7 / 20 ========\n",
      "Training...\n",
      "  Batch   100  of    835.    Elapsed: 0:02:21.\n",
      "  current loss = 4.5798016799381e-05\n",
      "  Batch   200  of    835.    Elapsed: 0:04:43.\n",
      "  current loss = 2.663221675902605e-05\n",
      "  Batch   300  of    835.    Elapsed: 0:07:05.\n",
      "  current loss = 2.6945219360641204e-05\n",
      "  Batch   400  of    835.    Elapsed: 0:09:27.\n",
      "  current loss = 8.103477011900395e-05\n",
      "  Batch   500  of    835.    Elapsed: 0:11:49.\n",
      "  current loss = 3.763166751014069e-05\n",
      "  Batch   600  of    835.    Elapsed: 0:14:11.\n",
      "  current loss = 1.9616880308603868e-05\n",
      "  Batch   700  of    835.    Elapsed: 0:16:34.\n",
      "  current loss = 5.748944386141375e-05\n",
      "  Batch   800  of    835.    Elapsed: 0:18:56.\n",
      "  current loss = 0.00016599809168837965\n",
      "Average training loss = 0.003060177757298132\n",
      "Average training accuracy = 0.9991298652694611\n",
      "\n",
      "Running Validation ...\n",
      "Average validation loss = 0.03341771818822865\n",
      "Average validation accuracy = 0.9946236559139785\n",
      "saving model...\n",
      "\n",
      "======== Epoch 8 / 20 ========\n",
      "Training...\n",
      "  Batch   100  of    835.    Elapsed: 0:02:21.\n",
      "  current loss = 2.5867038857541047e-05\n",
      "  Batch   200  of    835.    Elapsed: 0:04:43.\n",
      "  current loss = 2.241927904833574e-05\n",
      "  Batch   300  of    835.    Elapsed: 0:07:05.\n",
      "  current loss = 3.067962097702548e-05\n",
      "  Batch   400  of    835.    Elapsed: 0:09:27.\n",
      "  current loss = 4.674004594562575e-05\n",
      "  Batch   500  of    835.    Elapsed: 0:11:49.\n",
      "  current loss = 1.3535796824726276e-05\n",
      "  Batch   600  of    835.    Elapsed: 0:14:12.\n",
      "  current loss = 1.1874242773046717e-05\n",
      "  Batch   700  of    835.    Elapsed: 0:16:34.\n",
      "  current loss = 8.076101948972791e-05\n",
      "  Batch   800  of    835.    Elapsed: 0:18:56.\n",
      "  current loss = 0.0002298110193805769\n",
      "Average training loss = 0.002230058593320105\n",
      "Average training accuracy = 0.9994292664670659\n",
      "\n",
      "Running Validation ...\n",
      "Average validation loss = 0.037586623460908894\n",
      "Average validation accuracy = 0.9933635752688172\n",
      "saving model...\n",
      "\n",
      "======== Epoch 9 / 20 ========\n",
      "Training...\n",
      "  Batch   100  of    835.    Elapsed: 0:02:21.\n",
      "  current loss = 0.00012089891242794693\n",
      "  Batch   200  of    835.    Elapsed: 0:04:43.\n",
      "  current loss = 5.61635461053811e-05\n",
      "  Batch   300  of    835.    Elapsed: 0:07:05.\n",
      "  current loss = 2.4137876607710496e-05\n",
      "  Batch   400  of    835.    Elapsed: 0:09:28.\n",
      "  current loss = 2.9628872653120197e-05\n",
      "  Batch   500  of    835.    Elapsed: 0:11:50.\n",
      "  current loss = 2.6227829948766157e-05\n",
      "  Batch   600  of    835.    Elapsed: 0:14:12.\n",
      "  current loss = 3.5144443245371804e-05\n",
      "  Batch   700  of    835.    Elapsed: 0:16:34.\n",
      "  current loss = 4.897765029454604e-05\n",
      "  Batch   800  of    835.    Elapsed: 0:18:57.\n",
      "  current loss = 0.02060527354478836\n",
      "Average training loss = 0.002432721179289064\n",
      "Average training accuracy = 0.9992702095808383\n",
      "\n",
      "Running Validation ...\n",
      "Average validation loss = 0.03359079643499866\n",
      "Average validation accuracy = 0.9936749891386988\n",
      "saving model...\n",
      "\n",
      "======== Epoch 10 / 20 ========\n",
      "Training...\n",
      "  Batch   100  of    835.    Elapsed: 0:02:21.\n",
      "  current loss = 1.6124786270665936e-05\n",
      "  Batch   200  of    835.    Elapsed: 0:04:43.\n",
      "  current loss = 1.3001495972275734e-05\n",
      "  Batch   300  of    835.    Elapsed: 0:07:05.\n",
      "  current loss = 2.096612297464162e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b4a6746bec5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  current loss = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# average loss across batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "\n",
    "for epoch_i in range(0,epochs):\n",
    "    print(\"\")\n",
    "    print(\"======== Epoch {:} / {:} ========\".format(epoch_i + 1, epochs))\n",
    "    print(\"Training...\")\n",
    "    t0 = time.time()\n",
    "    model.train() \n",
    "    running_loss = 0 \n",
    "    train_steps = 0 \n",
    "    train_accuracy = 0 \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print(\"  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.\".format(step, len(train_dataloader), elapsed))\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        b_labels = b_labels.float()\n",
    "        #optimizer.zero_grad() \n",
    "        outputs = model(b_input_ids, b_input_mask) \n",
    "        outputs = outputs.flatten()  \n",
    "        \n",
    "        loss = criterion(outputs, b_labels)\n",
    "        if step % 100 == 0 and not step == 0: \n",
    "            print(\"  current loss = {}\".format(loss.item())) # average loss across batch \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step() \n",
    "        scheduler.step() \n",
    "        model.zero_grad()\n",
    "        running_loss += loss.item()    \n",
    "        \n",
    "        outputs = outputs.detach().cpu().numpy() \n",
    "        b_labels = b_labels.to('cpu').numpy()  \n",
    "        classes = np.where(outputs > 0.5, 1, 0)\n",
    "        \n",
    "        train_accuracy += np.sum(classes == b_labels)/len(b_labels)\n",
    "        \n",
    "        train_steps += 1 \n",
    "        \n",
    "    print(\"Average training loss = {}\".format(running_loss / len(train_dataloader))) \n",
    "    print(\"Average training accuracy = {}\".format(train_accuracy / train_steps))\n",
    "    \n",
    "    print(\"\") \n",
    "    print(\"Running Validation ...\")\n",
    "    t0 = time.time()\n",
    "    model.eval() \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    eval_steps = 0 \n",
    "    for batch in val_dataloader: \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        b_labels = b_labels.float() \n",
    "        with torch.no_grad():     \n",
    "            outputs = model(b_input_ids, b_input_mask)\n",
    "        outputs = outputs.flatten() \n",
    "        loss = criterion(outputs, b_labels) \n",
    "        eval_loss += loss.item()   \n",
    "        \n",
    "        outputs = outputs.detach().cpu().numpy() \n",
    "        b_labels = b_labels.to('cpu').numpy()  \n",
    "        classes = np.where(outputs > 0.5, 1, 0)\n",
    "        \n",
    "        eval_accuracy += np.sum(classes == b_labels)/len(b_labels) \n",
    "        \n",
    "        eval_steps += 1\n",
    "        \n",
    "    avg_val_loss = eval_loss / len(val_dataloader)  \n",
    "    avg_val_accuracy = eval_accuracy / eval_steps \n",
    "    print(\"Average validation loss = {}\".format(avg_val_loss)) \n",
    "    print(\"Average validation accuracy = {}\".format(avg_val_accuracy))\n",
    "    \n",
    "    savepath = './storage/hanbert_models/model'\n",
    "    print(\"saving model...\")\n",
    "    torch.save({'state_dict':model.state_dict()}, savepath + str(epoch_i+1) + '.pth.tar') \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = CustomBERTModel() \n",
    "checkpoint = torch.load('./storage/hanbert_models/model7.pth.tar') \n",
    "best_model.load_state_dict(checkpoint['state_dict']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model.eval() \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_sequences = torch.tensor(test_input_sequences)\n",
    "test_attention_masks = torch.tensor(test_attention_masks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "test_set = TensorDataset(test_input_sequences, test_attention_masks) \n",
    "test_sampler = SequentialSampler(test_set) \n",
    "test_dataloader = DataLoader(test_set, sampler = test_sampler, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Quadro P6000\n"
     ]
    }
   ],
   "source": [
    "# define device again \n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time() \n",
    "predictions = [] \n",
    "for step, batch in enumerate(test_dataloader):  \n",
    "    if step % 100 == 0 and not step == 0: \n",
    "        elapsed = format_time(time.time() - t0) \n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "    b_input_ids, b_input_mask = batch \n",
    "    with torch.no_grad():\n",
    "        outputs = best_model(b_input_ids, b_input_mask) \n",
    "    outputs = outputs.flatten() \n",
    "    predictions.append(outputs) \n",
    "        \n",
    "print(\"converting prediction array to numpy...\")\n",
    "predictions = np.asarray(predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
