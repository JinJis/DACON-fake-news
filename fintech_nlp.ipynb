{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pylab as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, Conv2DTranspose, MaxPooling2D, AveragePooling2D, BatchNormalization, concatenate, Input, ConvLSTM2D, Reshape, Conv3D, Flatten, LSTM, GRU, Dense,Dropout, Add\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import re \n",
    "\n",
    "import nltk # for stopwords \n",
    "from nltk.corpus import stopwords\n",
    "import gensim # for Word2Vec embeddings \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from konlpy.tag import Mecab \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./storage/fintech_nlp/news_train.csv')\n",
    "test = pd.read_csv('./storage/fintech_nlp/news_test.csv') \n",
    "submission = pd.read_csv('./storage/fintech_nlp/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the preprocessed data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118745, 23), (118745, 61), (142565, 61), (142565, 23))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.load('./storage/fintech_nlp/y_train.npy') \n",
    "train_title = np.load('./storage/fintech_nlp/train_title_padded_x.npy')\n",
    "train_content = np.load('./storage/fintech_nlp/train_content_padded_x.npy')\n",
    "test_content = np.load('./storage/fintech_nlp/test_content_padded.npy') \n",
    "test_title = np.load('./storage/fintech_nlp/test_title_padded.npy') \n",
    "\n",
    "train_title.shape, train_content.shape, test_content.shape, test_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_content = 41573 \n",
    "vocab_title = 9197 \n",
    "embedding_vec_title = 16 \n",
    "embedding_vec_content = 64\n",
    "\n",
    "title_length = 23 \n",
    "content_length = 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 61)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 61, 64)       2660672     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 61, 256)      197632      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 23)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 23, 16)       147152      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           16448       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 256)          148480      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 320)          0           bidirectional[0][0]              \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            321         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,170,705\n",
      "Trainable params: 3,170,705\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():  \n",
    "    input_title = Input((title_length))\n",
    "    input_content = Input((content_length)) \n",
    "    \n",
    "    emb_title = Embedding(vocab_title,embedding_vec_title)(input_title)\n",
    "    lstm_title = Bidirectional(LSTM(128, return_sequences=False))(emb_title)\n",
    "\n",
    "    emb_text = Embedding(vocab_content,embedding_vec_content)(input_content)\n",
    "    lstm_text = Bidirectional(LSTM(128, return_sequences=True))(emb_text)\n",
    "    max_pool_text = GlobalMaxPool1D()(lstm_text)\n",
    "    dropout_1_text = Dropout(0.1)(max_pool_text)\n",
    "    dense_1_text = Dense(64, activation='relu')(dropout_1_text)\n",
    "    dropout_2_text = Dropout(0.1)(dense_1_text)\n",
    "\n",
    "    out = concatenate([lstm_title,dropout_2_text],axis=-1)\n",
    "    output=Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "    model = Model(inputs=[input_title, input_content], outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model \n",
    "\n",
    "model = build_model() \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94996 samples, validate on 23749 samples\n",
      "Epoch 1/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 9.4167e-05 - accuracy: 1.0000\n",
      "Epoch 00001: val_loss improved from inf to 0.08159, saving model to ./storage/fintech_nlp_first_submission/epoch_001_val_0.082.h5\n",
      "94996/94996 [==============================] - 26s 272us/sample - loss: 9.4023e-05 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9855\n",
      "Epoch 2/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 1.0088e-04 - accuracy: 1.0000\n",
      "Epoch 00002: val_loss improved from 0.08159 to 0.06970, saving model to ./storage/fintech_nlp_first_submission/epoch_002_val_0.070.h5\n",
      "94996/94996 [==============================] - 26s 272us/sample - loss: 1.0074e-04 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9877\n",
      "Epoch 3/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 7.5510e-05 - accuracy: 1.0000\n",
      "Epoch 00003: val_loss did not improve from 0.06970\n",
      "94996/94996 [==============================] - 23s 246us/sample - loss: 7.5395e-05 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9867\n",
      "Epoch 4/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 6.8506e-05 - accuracy: 1.0000\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06970\n",
      "94996/94996 [==============================] - 23s 245us/sample - loss: 6.8468e-05 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9857\n",
      "Epoch 5/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 6.2142e-05 - accuracy: 1.0000\n",
      "Epoch 00005: val_loss did not improve from 0.06970\n",
      "94996/94996 [==============================] - 23s 245us/sample - loss: 6.2049e-05 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9865\n",
      "Epoch 6/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 5.1039e-05 - accuracy: 1.0000\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06970\n",
      "94996/94996 [==============================] - 23s 246us/sample - loss: 5.0964e-05 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9870\n",
      "Epoch 7/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 5.9603e-05 - accuracy: 1.0000\n",
      "Epoch 00007: val_loss did not improve from 0.06970\n",
      "94996/94996 [==============================] - 24s 250us/sample - loss: 5.9519e-05 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9865\n",
      "Epoch 8/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 3.2788e-05 - accuracy: 1.0000\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06970\n",
      "94996/94996 [==============================] - 23s 246us/sample - loss: 3.2748e-05 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9867\n",
      "Epoch 9/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 4.4869e-05 - accuracy: 1.0000\n",
      "Epoch 00009: val_loss did not improve from 0.06970\n",
      "94996/94996 [==============================] - 23s 246us/sample - loss: 4.4800e-05 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9865\n",
      "Epoch 10/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 5.1967e-05 - accuracy: 1.0000\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06970\n",
      "94996/94996 [==============================] - 23s 246us/sample - loss: 5.1930e-05 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9867\n",
      "Epoch 11/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 3.5347e-05 - accuracy: 1.0000\n",
      "Epoch 00011: val_loss did not improve from 0.06970\n",
      "94996/94996 [==============================] - 23s 247us/sample - loss: 3.5299e-05 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9867\n",
      "Epoch 12/200\n",
      "94848/94996 [============================>.] - ETA: 0s - loss: 3.8611e-05 - accuracy: 1.0000\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06970\n",
      "94996/94996 [==============================] - 23s 246us/sample - loss: 3.8556e-05 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "model_path = './storage/fintech_nlp_first_submission/epoch_{epoch:03d}_val_{val_loss:.3f}.h5'\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.5)\n",
    "checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10) \n",
    "\n",
    "history = model.fit(x=[train_title,train_content],\n",
    "                    y=y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=200,\n",
    "                    verbose=1,\n",
    "                    validation_split = 0.2, \n",
    "                    callbacks = [learning_rate_reduction,checkpoint,early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the prediction using the trained model and generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model('./storage/fintech_nlp_first_submission/epoch_002_val_0.028.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict([test_title,test_content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pred = np.where(predictions > 0.5, 1,0).reshape(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5989198e-01],\n",
       "       [1.3560057e-04],\n",
       "       [6.8873167e-05],\n",
       "       ...,\n",
       "       [9.9999988e-01],\n",
       "       [9.9999404e-01],\n",
       "       [9.9999404e-01]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEWS00237_1</td>\n",
       "      <td>0.359892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEWS00237_2</td>\n",
       "      <td>0.000136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEWS00237_3</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEWS00237_4</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEWS00237_5</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id      info\n",
       "0  NEWS00237_1  0.359892\n",
       "1  NEWS00237_2  0.000136\n",
       "2  NEWS00237_3  0.000069\n",
       "3  NEWS00237_4  0.000023\n",
       "4  NEWS00237_5  0.000229"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEWS00237_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEWS00237_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEWS00237_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEWS00237_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEWS00237_5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  info\n",
       "0  NEWS00237_1     0\n",
       "1  NEWS00237_2     0\n",
       "2  NEWS00237_3     0\n",
       "3  NEWS00237_4     0\n",
       "4  NEWS00237_5     0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['info'] = class_pred \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./storage/bidirectional_lstm_first_submission_classes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
