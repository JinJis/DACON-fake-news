
# Background
If you see the test data sets, you will notice that each data point consists of `title` and `content`. The real data point hereby means the combination of a title and randomly picked sentence from the news article.

Meaning `set(real title, real content)` where `real_content = a sentence picked from real article`.

By analyzing the pattern of fake news training set, two features could be noticed.

1. Let's say authentic data = `set(real title, real content)`, then we can make fake news by adding `!` or `"` to the front or end of the content.
2. Shuffling. Let's say we have `set(news1 real title, news1 real content)`, `set(news2 real title, news2 real content)`. There is a pattern where fake news is generated by shuffling two sets of real news but mismatching title or content to each other. For example, we can make fake news by having real title from news1 but content from any sentence from news2.

<p><br></p>

# Objective
If we count real set over fake set, fake counts more than the real one. In every *Binary Classification* problem, this kind of situation is called `Class Imbalance`, and can have serious impact on training.

Thus we need to **synthetically generate fakes news** so that the ratio between real and fakes are as same as possible.

<p><br></p>

# Implementation

This is not automated script that accepts input file, scrape news, shuffle and gives out output to the executor. You need to understand below steps and run appropriate script accordingly with proper input files.

<p><br></p>

## General Flow

Below is the illustration of the general flow for generating fake news. Note that two individual jobs are executed for two input files, and the outputs are processed together to beget the final fake news combinations.
<p align="center">
  <img src="https://github.com/JinJis/DACON-fake-news-identification/blob/main/web_scrapper/image/dacon_general.png" width="80%" title="hover text">
</p>

<p><br></p>

## Steps Explained

### (1) Scrape News Data from Collected Domain

> `links.json` file is composed of `domain` like `realestate.daum.net` as key and list(`[title, news_url]`) like `["\"3년 전 분양가로 3가구 공급\" vs \"아파트명 바꾸고 완판\"", "https://realestate.daum.net/news/detail/main/20200514114427699"]`, as value.

* **Manually inspect HTML tags** of each domains' article and make rule.
  * Each domain has different rule for storing news content so need to manually inspect.
* **Scrape contents part** of the news article by using Beautifulsoup.
* **Extract content** using the rule stated above.
* **Parse it by every sentence** that should be readable in Korean using **NLTK** (Natual Language Tool Kit)
  * This is because the scraped result may include some unreadable sentence like `#SF!@EQDSD`
* **Save the result** in form of `{"title": ["content1", "content2" ... ]}`

<p><br></p>

### (2) Generate Fake News By Shuffling

> Now we can generate first version of fake news by shuffling title and contents.

* Set how many contents will be stored in each title of news.
* Exclude the **index of the title** picked.
* Get **any title** from data except for the index picked in above step.
* **Pick contents** from the randomly picked title above. This should be done randomly too.
* Save contents as list and save it in forms of `"news1_title": ["news2_content1", "newsN_contentM" ... ]`

<p align="center">
  <img src="https://github.com/JinJis/DACON-fake-news-identification/blob/main/web_scrapper/image/links_to_fake.png" width="100%" title="hover text">
</p>

*Please note how the schema of each data is modified as they go through data processing.*

<p><br></p>

### (3) Preprocess given News Train sets to match format

> The competition manager provided with some number of data as training set. As our algorithm already used this data to train itself, it is crucial for us to exclude any combination of data set from the generated fake news combination done in (1) ~ (2).

* Filter news_train.csv (provided by competition manager) file in forms of (1) and (2)

<p align="center">
  <img src="https://github.com/JinJis/DACON-fake-news-identification/blob/main/web_scrapper/image/train_to_filtered.png" width="80%" title="hover text">
</p>

*Data given by DACON competition are correctly converted in forms of our own data schema*

<p><br></p>

### (4) Discard Any Duplicate Combination from (2)

> Finally, exclude any duplicate combination of title-content combination in (3) from the result of (2). This will ensure accuracy and reliability of algorithm we will train.

<p align="center">
  <img src="https://github.com/JinJis/DACON-fake-news-identification/blob/main/web_scrapper/image/final_fake_result.png" width="350" title="hover text">
</p>
